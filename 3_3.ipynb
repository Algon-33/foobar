{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Take in a maze. Walls are 1s and movable space is a 0. Paths are rectilinear only.\\nYou can remove at most one wall from each maze.\\nFind the shortest path to the exit.\\n\\nShortest path function should be a simple djistrkra's algorithm. \\nChecking if the maze is connected or not can be simply done by just filling in all the zero's from the start point.\\nFinding the wall that would result in the shortest path is somewhat more tricky. \\n    You want to find wall which have a blank space on the filled in side i.e.\\n    they neighbour a filled in node and an empty node.\\n        You can possibly do this by search for walls along the edges that are beyond\\n        the filled in nodes and following the RHS of the connected walls and seeing\\n        if they connect split the start and finish nodes\\n        \\n        Maybe pre-compute these walls by creating a graph for the walls and seeing \\n        which ones split the start and end points off from each other?\\n            Ech, sounds more tedious.\\n        \\n    Then find the shortest paths from the start to each of these nodes, prioritising those\\n    with the lest norm_1 distance from the start and end point, as well as those with the shortest\\n    paths to them.\\n    \\n    Order them as above, then go through each and apply djistrika's algorithm \\n    to each.\\n        Or perhaps just remove all of them and then apply the shortest path algorithm?\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTES: Check if writing things out in full takes away your motiviation. Suggested solution: write psuedocode as you go so you \n",
    "#can see how underspecified things are\n",
    "#in particular, the exact form things take will depend on your data-structures and the functions you want will affect your\n",
    "#data structures. Suggested solution: Keep the funtionality you want in mind, and just go for the simplest possible soultion \n",
    "# or just the one that first springs to mind. Recall which ideas you keep on using in your psuedoalgorithm.\n",
    "#Once I felt that the code I was writing would need some new vars that would need to be changed later on, but I hadn't written \n",
    "#about that part yet. Suggested solution: write outlines as you go along, and if you feel something is needed later on, just\n",
    "#stick it in the outline like you would when writing a zettlekasten. \n",
    "\n",
    "#If you have some complexity in your function definition, try moving it back to the input so you don't screw up your function.\n",
    "    #This might be bad advice bc. you're pushing complexity onto the user. What you really want, is to automate the transformations\n",
    "    #you perform in your head as much as possible. \n",
    "        #IDEA: GOOD PROGRAMMING STYLE RESULTS IN YOU HAVING TO KEEP TRACK OF FEWER THINGS.\n",
    "            #This idea seems to have some merit. True for clean interfaces, for cases where functions are built to handle\n",
    "            #a wide variety of outputs,\n",
    "            #for cases where the intuitive abstractions you have match what the system actually does etc.\n",
    "            #IDEA: (But the thought that led to this thought was) GOOD PROGRAMMING STYLE INVOLVES AUTOMATING EVERY MENTAL PROCESS\n",
    "            #YOU HAVE IN THE SAME WAY YOU WERE DOING THEM. \n",
    "            #Flip side is that the you should think in a way that matches the problem domain and the computer, so your mental\n",
    "            #processes can be straightforwardly ported to code.\n",
    "            \n",
    "            #IDEA: Programming is the art\n",
    "#Your tests should always be about checking if the input X leads to the results Y that you expect, so naturally your tests\n",
    "#should give you that ability. AND, if you do a test and it fails, you damn well better show what the output leading to the failure\n",
    "#was. Maybe even the input, if that is possible. \n",
    "    #Maybe in each test of f that relies on functions g_i we should call the tests for g_i within them? Perhaps that's what they\n",
    "    #mean by an end to end test\n",
    "    \n",
    "    #You would like a function of the form test s.t. test(function(args), answer ) tests if the function output on args gives an \n",
    "    #answer that you'd like. This fits your current programming style the best. And perhaps just fits a functional style better\n",
    "    #in general.\n",
    "    \n",
    "    #On the other hand, if you were testing an object you might want something like test(obj, custom_test_cases)\n",
    "    #with a whole suite of custom test cases to insure that you understand what things in the objects context which might\n",
    "    #be a lot weirder than you think bc. you have a leaky abstraction regarding the interface between objects. \n",
    "        #SO you might like to test objects in pairs or so on and so forth.\n",
    "        #This is arguably a better fit for another style, maybe OOP or perhaps someone who is working with systems that predictably\n",
    "        #have complex interfaces. \n",
    "        \n",
    "    #The former would be easy enough to implement in mathematica, or lisp. So could the idea about\n",
    "    #recursively testing the function you submit and the things generating its arguements, or the functions that\n",
    "    #are used internally. Or testing things line by line and having a check for what's going throught the function and seeing it\n",
    "    #more like a graph with functions at the vertices.\n",
    "    \n",
    "    #The latter context focused style could also be done there, but it feels like it would make a LOT more sense for a style\n",
    "    #which involves keeping track of loads of external state. I think that might not be a functional style, but I'm not sure.\n",
    "    #Regardless, a testing suite that's more focused on picturing the code as doing things to a whole bunch of state would be\n",
    "    #a better fit for OOP.\n",
    "        #I checked some python source code, and what stood out to me was that they used assert instead of check if a==b and\n",
    "        #outputting an error if those conditions obtain.\n",
    "            #IDEA: SO alternatively, you could try just turn the tests you perform manually into assertions and \n",
    "            #leave things at that. \n",
    "            \n",
    "            #IDEA: Programming is the art of designing mental processes towards some goal s.t. they can and will be automated\n",
    "                #IDEA: Beautiful programming is reasoning straightforwardly automatable reasoning\n",
    "            #IDEA: The above implies that programmers will obviously go around automating their day to day lives.\n",
    "        #They didn't pass in all the context needed to isolate a function i.e. if they need some function to perform a test\n",
    "        #they'll just call it, assuming it has been defined somewhere that the test function can access\n",
    "        #They do tests which require assertions and value_error raising seperately.\n",
    "        #They also had if statements that nested a few levels deep and plenty of non-one liners.\n",
    "    #If programming differed from maths in that you assume mathematical objects only interact with other things through externally\n",
    "    #obvious relations, then why would it be the case that maths is like that? Is it because mathematicians like to abstract\n",
    "    #away the details of things like state that have to do with other objects, or modular concepts are just easier to work with?\n",
    "    #Also, what's the above have to say on this idea? Because functional programming is clearly something Patrick knows about, and \n",
    "    #he still views maths as being different to programming. In that case, it might be more about rapid feedback from the machine.\n",
    "    \n",
    "    \n",
    "    \n",
    "    #I had a thought in the shower. I was reflecting on the way I was noticing problems as I was coding, and how that made me\n",
    "    #more reflective or \"alive\" i.e. I could pay more attention to things \n",
    "        #HYPOTHEIS: Perhaps my coming alive as I start writing down thoughts and noticing ever more things is a progression from\n",
    "        #noticing problems and paying attention to things -> reflection. Or maybe the other way round.\n",
    "        #EXPERIMENT: Try testing this capacity as you are writing.\n",
    "            #IDEA: for data, focus on Whatever happend as I wrote that document about \"codex for writing features\" that \n",
    "            #I sent to Patrick.\n",
    "    #Anyway, I was wondering how this could be true and I started thinking about shard theory\n",
    "        #Things I missed in my thoughts on shards that TT and QP got, which seemed important to their progress. Context being\n",
    "        #key to shard activation and the process of shard formation. \n",
    "        #Others have almost certainly come up with this exact theory before hand. In fact, I probably drew on others' almost \n",
    "        #completely in forming this worldview. \n",
    "            # I don't like admitting that. But it is possible, and probable after accounting for some bias. Maybe not certain, but\n",
    "            #probable. \n",
    "                #I would like to be able to say there is a shot I came up with it myself. And maybe I did. Or perhaps I obtained\n",
    "                #it from comments on GPT-3 by Yudkowsky or that book review on SSC/ACX which mentioned lampray neurology.\n",
    "        #I should probably write about this, as well as how I differ from TT. Also possibly mention my own experiences in using the\n",
    "        #idea and maybe how I could have come up with more stuff myself earlier e.g. thinking about how to create shards or an \n",
    "        #AI design mindset. That seems downstream of usefully connecting it to alignment, but whatever.\n",
    "    #Now, my thoughts were that perhaps I was switching context to a mode which was historically more similair to the ones\n",
    "    # in which I solved problems, or perhaps I was activating some representation in my brain which corrseponded to the general\n",
    "    #idea of problem, or some representation that was more deliberate in kind, and these thoughts fired up my problem solving \n",
    "    #shards\n",
    "        # (e.g. like when I'm reflecting on how I could have solved a problem better, I'm maybe not as frustrated or focused\n",
    "        #on details or somesuch. And because of the practice I have with that, I've built up some problem solving shards like \n",
    "        #\"reversal\" that will only fire when I'm in a similair mood/mental context. But these shards aren't connected to \n",
    "        #the problem solving context itself. Which leaves the problem of all my other problem solving shards.)\n",
    "        \n",
    "        #Maybe this has something to do with all those \"cognitive patterns that are burnt into memory\" s.t. that happen in Yud's\n",
    "        #fics when a character gets dumber.\n",
    "            #IDEA: See if those scenes in mad investor chaos correspond to your thoughts on what happens as you get dumber and \n",
    "            #connecting it to this body of thought.\n",
    "    #Or maybe it was the context of being reflective at all, which does have the prediction that as I try to be more reflective\n",
    "    #I should naturally get better at problem solving.\n",
    "        #DATA: Which does broadly match the data I have about being able to reflect better and better after listening to \n",
    "        #my own thoughts for a while. But that tends to have a longer term affect \n",
    "            #DATA: I did actually try programming and thinking for a while before this.\n",
    "            #Hypothesis: My problem solving capabilities fire up my self reflection capbilities, which can in turn improve\n",
    "            #my problem solving capabilities.\n",
    "        #IDEA: Also, focus on what happens as you get dumber\n",
    "    #Personally, I think I should note down the context I have as my mind is awakening.\n",
    "    #Now, of course, having more mental resources \"available\" could occur as I move away from a migranous state. I am quite sure\n",
    "    #that at some level this must be true, and perhaps it is more related to higher executive functioning or somesuch like in\n",
    "    #those papers on my microsoft surface. But the point is, that this could be psychological and or neurological in kind. \n",
    "    \n",
    "    \n",
    "#You should try solving the problems a couple of different ways.\n",
    "#DON'T right expansive or complex unit tests until you've settled on what you need, because you may need to later abstract\n",
    "#your functions. Ideally, this shouldn't matter if your unit tests are a natural fit to the problem.\n",
    "#But if they aren't e.g. you've included a bunch of other dependancies to other functions as input, then you're buggered.\n",
    " \n",
    "    \n",
    "\"\"\"Take in a maze. Walls are 1s and movable space is a 0. Paths are rectilinear only.\n",
    "You can remove at most one wall from each maze.\n",
    "Find the shortest path to the exit.\n",
    "\n",
    "Shortest path function should be a simple djistrkra's algorithm. \n",
    "Checking if the maze is connected or not can be simply done by just filling in all the zero's from the start point.\n",
    "Finding the wall that would result in the shortest path is somewhat more tricky. \n",
    "    You want to find wall which have a blank space on the filled in side i.e.\n",
    "    they neighbour a filled in node and an empty node.\n",
    "        You can possibly do this by search for walls along the edges that are beyond\n",
    "        the filled in nodes and following the RHS of the connected walls and seeing\n",
    "        if they connect split the start and finish nodes\n",
    "        \n",
    "        Maybe pre-compute these walls by creating a graph for the walls and seeing \n",
    "        which ones split the start and end points off from each other?\n",
    "            Ech, sounds more tedious.\n",
    "        \n",
    "    Then find the shortest paths from the start to each of these nodes, prioritising those\n",
    "    with the lest norm_1 distance from the start and end point, as well as those with the shortest\n",
    "    paths to them.\n",
    "    \n",
    "    Order them as above, then go through each and apply djistrika's algorithm \n",
    "    to each.\n",
    "        Or perhaps just remove all of them and then apply the shortest path algorithm?\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dijkstra_algorithm\\n\\nYou have a graph. Each node has neighbours Z connected by edges E(Z,n).\\nThere is a cost associated to edges of a graph i.e. for \\nneighbours m,n the cost is C(m,n). \\n\\nWe wish to find the minimal-path cost between two nodes, a and z. \\n\\nTo do this, first assign some costs to all the nodes and a. We define this \\nfunction L: nodes -> R.\\nWe assume that L(x) >= the minimal path cost from a to x. So we initialise \\nL(x) to some huge number e.g. 10^10.\\n\\nNow, to find C(a,z) we write \\nC(a,z) = minimum_{x \\\\in N(z)} L(x) + C(x,z)\\nn(a,z) = argmin_{x in N(z)} L(x) + C(x,z)\\n\\nnu(x,m) = \\\\lambda x: n(a,x) if m = 1 else nu( n(a,x), m-1)\\n\\nSuppose that we have L(x) >= C(a,x)\\n\\nC(a,y) = L( nu(x,1) ) + C(nu(x,1), x)\\n\\nC(a,x) = L(nu(x,1)) + C( nu(x,1), x ) >= C(a, nu(x,1)) + C(nu(x,1), x)\\nC(a,x) >= C(a, nu(x,1)) + C(nu(x,1), x) =\\nL(nu(x,1)) + C(nu(x,2), nu(x,1)) + C(nu(x,1),x)\\n...\\nC(a,x) >= C(a, nu(x,m)) + C(nu(x,m-1), nu(x,m-2)) + ... C(nu(x,2),nu(x,1)) + \\nC(nu(x,1),x)\\n\\n\\n\\n\\n\\n\\nProve that for a chain n paces long, this path is indeed minimal. This is easily true if it is the caase that L(x) for the \\nun-evaluated nodes is larger than any L(z) where z is a neighbour of the next level of unevaluated nodes. This is true bc.\\nof the ridiciulous value we chose for \\x0corall x L(x). \\n\\nSo this has the issue of not computing optimal path lengths when there are multiple optima, but maybe \\nwe don\\'t need to worry about that.\\n    Still, it would be nice to sanity check that.\\n\\n\\n\\nSo dijkstra_algorithm takes in a graph, a start and end node and a neighbour cost function.\\n\\nYou then check the neighbours of the starting point and define the minimal path cost to them as C(a,x). Then add those nodes \\nto a temporary stack and a permanent stack.\\n\\nIn the next level, you check the neighbours of the stack, discounting nodes that have appeared already.\\nCompute their cost by searching over their neighbours and extremising C(a,x). Add them to the temporary stack, and \\nmove the prior nodes onto the permanent stack.\\n    I keep on saying stack. Is that what I mean? Or do I mean a heap or something?\\nThen repeat until after reach reach the goal node or there are no new nodes left.\\nSubmit the costs and a flag saying whether or not the goal node was reached. \\n    \\nThen find all the potential walls to break, break them, and search for the extremal path. \\n    I think it would be fine if you just broke all the walls. \\n    To do that, you need to check final final nodes on the temporary stack and see if the walls surrounding them have any empty\\n    spaces as neighbours. \\n    \\n    Then just update the graph so that you add those walls which pass the test as potential nodes. \\n        They need to be update s.t. they have the right neighbours and their neighbours have them as a neighbour. \\n        That can be done by taking the wall\\'s indices, referring back to the array, checking what empty cells are neighbours of \\n        the wall and returning them as neighbours to that point. \\n            It would be nice if we had a datastucture that\\'s symmetric. Maybe an edge data-structure which updates the nodes\\n            it is connected to? \\n            \\n            \\n            OOH, that\\'s a nice idea. Just like in mathematics you try to reframe problems in terms of the core structures\\n            that you encounter, and try to formalise patterns you think in, you should do the same in programming.\\n\\nSo our wall breaker function needs the ability to add nodes to the graph, and find the neighbours of wall nodes s.t. they aren\\'t\\nalready included in our set of nodes for which we have computed path costs. \\n\\nAfter that, you just continue the Djiskra\\'s algorithm process, presumably by putting the neighbours of the wall points \\nyou just deleted onto the temporary stack, calculuate their path costs and continue on from their.\\n    That does imply that you want the ability to take in two stacks, one of all the points you\\'ve computed path costs for and\\n    another those you have just computed them for and then act as if you\\'re carrying on djistkra\\'s algorithm from their. \\n\\n\\n\\nSo the algorithm should consist of an outer loop and a function\\nF: node_stack*node_stack*path_costs*node_neighbour_generators*cost_function*goal_node --> \\nnode_stack*node_stack*path_costs*node_neighbour_generators*cost_function\\n    \\n    I suppose if you bundle up the cost function and the node_neighbour_generators you could have an easier time of it.\\n\\n    So you\\'d get a function of the form\\n    F: graph * goal_node*node_stack*node_stack*path_costs-> graph *node_stack*node_stack*path_costs\\nThe outer loop should take in the goal_node, the graph and have something like\\n\\nfire up and run F the first time\\n    \\nreceive results and check whether on whether or not the goalnode has been reached i.t. it has a path cost, which should be a \\ndict I suppose\\n    NOTE that you don\\'t have to check whether or not the node_stack is empty bc. it shouldn\\'t be if the goal node hasn\\'t been\\n    reached. So we know the results w/o having to make a flag or something.\\n    Just check each turn whether or not the goal_node has a path cost therefore, or was in the temporary stack.\\n    \\nThen run the wall breaker which should be a function of the form\\nwall_breaker: node_stack*node_stack -> wall_co_ordinates_stack (i.e. walls)\\n    You could probably compute the path costs to the walls here, as well as the costs to the new nodes after the walls, and\\n    all the edges you need I suppose. \\n        IMPORTANT: I think the edge should just be a function that spits out a set consisting of the nodes that it connects\\nUpdate the graph by getting the co-ordinate\\nThen run F again on the new graph with the nodes_which_were_walls on the temporary stack and the prior ones moved to the \\npermanent stack.\\n    \\nKeep going until we get to the goal state.\\n\\nAnd that\\'s our maze solver. \\n\\n\\n\\n\\nOur graph should be a set of nodes along with a set of edges. We want the ability to take something via it\\'s indices and attach\\nit to the graph. So perhaps each node should be of the form: value, indices? And we also need a set of edges.\\n    OK, for the sake of simplicity, I\\'m going to suggest we have this format\\n    node: (int,int)XList[(int,int)].\\n    We will have a function is_a_node: (int,int)-->bool = lambda x: 1 if node_array[i][j]==1 \\n        This will take in an array of nodes. We will have wall_breaker send an update list of indices which we should adjust to \\n        1 in a new array to make them into acceptable nodes.\\n        \\n\\n\\n    I am feeling a bit tired right now. I wonder if the process of outlining things makes me lazier? Perhaps tt feels internally \\n    like I have already \"finished\" as it were.  Or maybe I\\'m just rationalising right now.\\n    \\n    I feel like I should have typed out psuedocode as I went along.\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dijkstra_algorithm\n",
    "\n",
    "You have a graph. Each node has neighbours Z connected by edges E(Z,n).\n",
    "There is a cost associated to edges of a graph i.e. for \n",
    "neighbours m,n the cost is C(m,n). \n",
    "\n",
    "We wish to find the minimal-path cost between two nodes, a and z. \n",
    "\n",
    "To do this, first assign some costs to all the nodes and a. We define this \n",
    "function L: nodes -> R.\n",
    "We assume that L(x) >= the minimal path cost from a to x. So we initialise \n",
    "L(x) to some huge number e.g. 10^10.\n",
    "\n",
    "Now, to find C(a,z) we write \n",
    "C(a,z) = minimum_{x \\in N(z)} L(x) + C(x,z)\n",
    "n(a,z) = argmin_{x in N(z)} L(x) + C(x,z)\n",
    "\n",
    "nu(x,m) = \\lambda x: n(a,x) if m = 1 else nu( n(a,x), m-1)\n",
    "\n",
    "Suppose that we have L(x) >= C(a,x)\n",
    "\n",
    "C(a,y) = L( nu(x,1) ) + C(nu(x,1), x)\n",
    "\n",
    "C(a,x) = L(nu(x,1)) + C( nu(x,1), x ) >= C(a, nu(x,1)) + C(nu(x,1), x)\n",
    "C(a,x) >= C(a, nu(x,1)) + C(nu(x,1), x) =\n",
    "L(nu(x,1)) + C(nu(x,2), nu(x,1)) + C(nu(x,1),x)\n",
    "...\n",
    "C(a,x) >= C(a, nu(x,m)) + C(nu(x,m-1), nu(x,m-2)) + ... C(nu(x,2),nu(x,1)) + \n",
    "C(nu(x,1),x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Prove that for a chain n paces long, this path is indeed minimal. This is easily true if it is the caase that L(x) for the \n",
    "un-evaluated nodes is larger than any L(z) where z is a neighbour of the next level of unevaluated nodes. This is true bc.\n",
    "of the ridiciulous value we chose for \\forall x L(x). \n",
    "\n",
    "So this has the issue of not computing optimal path lengths when there are multiple optima, but maybe \n",
    "we don't need to worry about that.\n",
    "    Still, it would be nice to sanity check that.\n",
    "\n",
    "\n",
    "\n",
    "So dijkstra_algorithm takes in a graph, a start and end node and a neighbour cost function.\n",
    "\n",
    "You then check the neighbours of the starting point and define the minimal path cost to them as C(a,x). Then add those nodes \n",
    "to a temporary stack and a permanent stack.\n",
    "\n",
    "In the next level, you check the neighbours of the stack, discounting nodes that have appeared already.\n",
    "Compute their cost by searching over their neighbours and extremising C(a,x). Add them to the temporary stack, and \n",
    "move the prior nodes onto the permanent stack.\n",
    "    I keep on saying stack. Is that what I mean? Or do I mean a heap or something?\n",
    "Then repeat until after reach reach the goal node or there are no new nodes left.\n",
    "Submit the costs and a flag saying whether or not the goal node was reached. \n",
    "    \n",
    "Then find all the potential walls to break, break them, and search for the extremal path. \n",
    "    I think it would be fine if you just broke all the walls. \n",
    "    To do that, you need to check final final nodes on the temporary stack and see if the walls surrounding them have any empty\n",
    "    spaces as neighbours. \n",
    "    \n",
    "    Then just update the graph so that you add those walls which pass the test as potential nodes. \n",
    "        They need to be update s.t. they have the right neighbours and their neighbours have them as a neighbour. \n",
    "        That can be done by taking the wall's indices, referring back to the array, checking what empty cells are neighbours of \n",
    "        the wall and returning them as neighbours to that point. \n",
    "            It would be nice if we had a datastucture that's symmetric. Maybe an edge data-structure which updates the nodes\n",
    "            it is connected to? \n",
    "            \n",
    "            \n",
    "            OOH, that's a nice idea. Just like in mathematics you try to reframe problems in terms of the core structures\n",
    "            that you encounter, and try to formalise patterns you think in, you should do the same in programming.\n",
    "\n",
    "So our wall breaker function needs the ability to add nodes to the graph, and find the neighbours of wall nodes s.t. they aren't\n",
    "already included in our set of nodes for which we have computed path costs. \n",
    "\n",
    "After that, you just continue the Djiskra's algorithm process, presumably by putting the neighbours of the wall points \n",
    "you just deleted onto the temporary stack, calculuate their path costs and continue on from their.\n",
    "    That does imply that you want the ability to take in two stacks, one of all the points you've computed path costs for and\n",
    "    another those you have just computed them for and then act as if you're carrying on djistkra's algorithm from their. \n",
    "\n",
    "\n",
    "\n",
    "So the algorithm should consist of an outer loop and a function\n",
    "F: node_stack*node_stack*path_costs*node_neighbour_generators*cost_function*goal_node --> \n",
    "node_stack*node_stack*path_costs*node_neighbour_generators*cost_function\n",
    "    \n",
    "    I suppose if you bundle up the cost function and the node_neighbour_generators you could have an easier time of it.\n",
    "\n",
    "    So you'd get a function of the form\n",
    "    F: graph * goal_node*node_stack*node_stack*path_costs-> graph *node_stack*node_stack*path_costs\n",
    "The outer loop should take in the goal_node, the graph and have something like\n",
    "\n",
    "fire up and run F the first time\n",
    "    \n",
    "receive results and check whether on whether or not the goalnode has been reached i.t. it has a path cost, which should be a \n",
    "dict I suppose\n",
    "    NOTE that you don't have to check whether or not the node_stack is empty bc. it shouldn't be if the goal node hasn't been\n",
    "    reached. So we know the results w/o having to make a flag or something.\n",
    "    Just check each turn whether or not the goal_node has a path cost therefore, or was in the temporary stack.\n",
    "    \n",
    "Then run the wall breaker which should be a function of the form\n",
    "wall_breaker: node_stack*node_stack -> wall_co_ordinates_stack (i.e. walls)\n",
    "    You could probably compute the path costs to the walls here, as well as the costs to the new nodes after the walls, and\n",
    "    all the edges you need I suppose. \n",
    "        IMPORTANT: I think the edge should just be a function that spits out a set consisting of the nodes that it connects\n",
    "Update the graph by getting the co-ordinate\n",
    "Then run F again on the new graph with the nodes_which_were_walls on the temporary stack and the prior ones moved to the \n",
    "permanent stack.\n",
    "    \n",
    "Keep going until we get to the goal state.\n",
    "\n",
    "And that's our maze solver. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Our graph should be a set of nodes along with a set of edges. We want the ability to take something via it's indices and attach\n",
    "it to the graph. So perhaps each node should be of the form: value, indices? And we also need a set of edges.\n",
    "    OK, for the sake of simplicity, I'm going to suggest we have this format\n",
    "    node: (int,int)XList[(int,int)].\n",
    "    We will have a function is_a_node: (int,int)-->bool = lambda x: 1 if node_array[i][j]==1 \n",
    "        This will take in an array of nodes. We will have wall_breaker send an update list of indices which we should adjust to \n",
    "        1 in a new array to make them into acceptable nodes.\n",
    "        \n",
    "\n",
    "\n",
    "    I am feeling a bit tired right now. I wonder if the process of outlining things makes me lazier? Perhaps tt feels internally \n",
    "    like I have already \"finished\" as it were.  Or maybe I'm just rationalising right now.\n",
    "    \n",
    "    I feel like I should have typed out psuedocode as I went along.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"outer code(graph, array, cost_function)\\n\\ninitial_vars\\n    maze_array, goal_node, start_node, cost_function \\n    \\nwhile goal_node_length_isn't_calculated_and_there_are_connected_nodes_left_to_calculate\\n    \\n    graph, temp_stack, perm_stack, path_costs = new_node_path_length_calculator\\n\\nif goal_node_length_isnt_calculated(path_costs, goal_node):\\n    \\n    walls_to_be_made_into_nodes, perm_stack, temp_stack, maze_array, wall_breaker(graph, perm_stack, temp_stack, array)\\n    \\n    new_graph, new_maze_array, perm_stack, temp_stack = new_graph_calculator(graph, walls_to_be_made_into_nodes, perm_stack, temp_stack)\\n\\n    while goal_node_length_isn't_calculated_and_there_are_connected_nodes_left_to_calculate\\n    \\n        graph, temp_stack, perm_stack, path_costs = new_node_path_length_calculator\\n    return path_costs\\n\\nelse:\\n    return_path_costs\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"outer code(graph, array, cost_function)\n",
    "\n",
    "initial_vars\n",
    "    maze_array, goal_node, start_node, cost_function \n",
    "    \n",
    "while goal_node_length_isn't_calculated_and_there_are_connected_nodes_left_to_calculate\n",
    "    \n",
    "    graph, temp_stack, perm_stack, path_costs = new_node_path_length_calculator\n",
    "\n",
    "if goal_node_length_isnt_calculated(path_costs, goal_node):\n",
    "    \n",
    "    walls_to_be_made_into_nodes, perm_stack, temp_stack, maze_array, wall_breaker(graph, perm_stack, temp_stack, array)\n",
    "    \n",
    "    new_graph, new_maze_array, perm_stack, temp_stack = new_graph_calculator(graph, walls_to_be_made_into_nodes, perm_stack, temp_stack)\n",
    "\n",
    "    while goal_node_length_isn't_calculated_and_there_are_connected_nodes_left_to_calculate\n",
    "    \n",
    "        graph, temp_stack, perm_stack, path_costs = new_node_path_length_calculator\n",
    "    return path_costs\n",
    "\n",
    "else:\n",
    "    return_path_costs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "#Feed in is_node and random matrix\n",
    "def test_is_node(test_function,matrix, **answer):\n",
    "    i = len(matrix);\n",
    "    j = len(matrix[0]);\n",
    "    try:\n",
    "        if np.array_equal(test_func(test_function(matrix), matrix), answer[\"answer\"]):\n",
    "            print(\"The is_node function generated your answer incorrectly.\")\n",
    "        else:\n",
    "            print(\"The is_node function outputs %s instead of the answer %s you submitted\" % (np.array_equal(test_function(is_node(matrix), matrix), answer[\"answer\"] )))\n",
    "    except (KeyError):\n",
    "        if np.array_equal(test_function(test_function(matrix)), matrix) and np.array_equal(test_function(matrix)+matrix, np.ones([i,j])):\n",
    "            print(\"Default test: is_node function is A-OK!\\n\")\n",
    "        else:\n",
    "            print(\"Either the matrix you input isn't an array of bools OR is_node isn't flipping all bools correctly \\n\")\n",
    "def test_co_ordinates(test_function, matrix_generator):\n",
    "    matrix = matrix_generator(None);\n",
    "    try:\n",
    "        ind = [[(j,i) for i in range(len(matrix[0]))]  for j in range(len(matrix))]\n",
    "        if ind == test_function(matrix):\n",
    "            print(\" co_ordinates is A-OK!\\n\")\n",
    "        else:\n",
    "            #Sure would be nice if you implemented some functionality to check which values differ. \n",
    "            print(\"Your co_ordinates function isn't generating the indices of each array element.\\n\")\n",
    "            print( \"This is %s the index of the (0,0) element the test co_ordinates produces. This %s is the correct index.\\n\" % (test_function(matrix), ind[0][0]) )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def test_keep(keep_function):\n",
    "    try:\n",
    "        ls = [i for i in range(100)]\n",
    "        pred = lambda x: 1 if x%37 ==0 else 0\n",
    "        keep_function(ls, pred)\n",
    "        ls = [np.array([1 for j in range(10)])  for i in range(10) ]\n",
    "        pred = lambda x: all([ i ==1  for i in x])\n",
    "        keep_function(ls, pred)\n",
    "        print(\"This function is probably OK\")\n",
    "    except:\n",
    "        print(\"Your keep function can't filter ints based on whether they are a multiple of 37 or check if a list contains np.ndarrays filled with ones\\n\")\n",
    "\n",
    "\n",
    "def test_neighbours_if_on_edge_E_index(node_index, neighbours, len_tuple, URLL_predicate_list, test_func):\n",
    "\n",
    "    BOOL = 1;\n",
    "    my_dict = {0: \"upper\", 1: \"right\", 2: \"lower\", 3:\"left\"}\n",
    "    for i in range(len(URLL_predicate_list)):\n",
    "        BOOL = BOOL * keep(neighbours, lambda neighbour_index: URLL_predicate_list[i](node_index, neighbour_index, len_tuple)) == test_func(node_index,  neighbours,len_tuple, URLL_predicate_list[i])\n",
    "        if BOOL ==0:\n",
    "            print(\"It looks like the neighbours_if_on_edge_E_index function to remove out of bound indices for the %s edge isn't working\" %my_dict[i])\n",
    "    \n",
    "    if (len_tuple[0]>2 and len_tuple[1]>2):\n",
    "        for i in range(len(URLL_predicate_list)):\n",
    "            BOOL = BOOL * keep([(2,1), (1,2), (0,1),(1,0)], lambda neighbour_index: URLL_predicate_list[i]((1,1), neighbour_index, len_tuple)) == [(2,1), (1,2), (0,1),(1,0)]\n",
    "            if BOOL ==0:\n",
    "                print(\"It looks like the part of the neighbours_if_on_edge_E_index function to keep in bound indices for the %s edge isn't working\" %my_dict[i])\n",
    "    if BOOL ==1:\n",
    "        print (\"neighbours_if_on_edge_E_index function is A-OK!\")\n",
    "\n",
    "\n",
    "def test_neighbours_if_on_all_edges_E_index(node_index, neighbours, len_tuple, URLL_predicate_list, test_func, answers):\n",
    "    BOOL = 1;\n",
    "    my_dict = {0: \"upper\", 1: \"right\", 2: \"lower\", 3:\"left\"};\n",
    "    try:\n",
    "        \n",
    "        for i in range(len(URLL_predicate_list)):\n",
    "            res = test_func(node_index,  neighbours,len_tuple, URLL_predicate_list[i]);\n",
    "            BOOL = BOOL * answers[\"answer\"][i] == res\n",
    "            if BOOL ==0:\n",
    "                print(\"On edge %s The function generated %s instead of the answer %s you submitted\" %(my_dict[i], res, answers[\"answer\"][i]))\n",
    "        if BOOL == 1:\n",
    "            print(\"The function generated the answer you submitted\")\n",
    "    except(Key_Error, IndexError):\n",
    "        \n",
    "        if (len_tuple[0]>2 and len_tuple[1]>2):\n",
    "            for i in range(len(URLL_predicate_list)):\n",
    "                BOOL = BOOL * keep([(2,1), (1,2), (0,1),(1,0)], lambda neighbour_index: URLL_predicate_list[i]((1,1), neighbour_index, len_tuple)) == [(2,1), (1,2), (0,1),(1,0)]\n",
    "                if BOOL ==0:\n",
    "                    print(\"Default test: It looks the function to keep in bound indices for the %s edge isn't working\" %my_dict[i])\n",
    "        if BOOL ==1:\n",
    "            print (\"This function is A-OK!\")\n",
    "\n",
    "def test_neighbours_if_on_an_edge_E_index(node_index, neighbours, len_tuple, edge_name, edge_func,  test_func, **answer):\n",
    "    if len(answer)>0:\n",
    "        BOOL = 1;\n",
    "        try:\n",
    "            ans = answer[\"answer\"]\n",
    "            res = keep(neighbours, lambda neighbour_index: edge_func(node_index, neighbour_index, len_tuple));\n",
    "            \n",
    "            if res != answer:\n",
    "                print(\"The neighbours_if_on_an_edge_E_index function's output was %s instead of the answer %s you submitted\" %(res, answer))\n",
    "            else:\n",
    "                print(\"The neighbours_if_on_an_edge_E_index function output the answer you submitted\")\n",
    "\n",
    "        except(KeyError):\n",
    "            pass\n",
    "    \n",
    "    else:\n",
    "        alt_res = test_func(node_index,  neighbours,len_tuple, edge_func);\n",
    "        BOOL = BOOL * res==alt_res\n",
    "\n",
    "        if BOOL ==0:\n",
    "            print(\"It looks like the function to remove out of bound indices for the %s edge isn't working\" %s)\n",
    "\n",
    "        elif (len_tuple[0]>2 and len_tuple[1]>2):\n",
    "\n",
    "            BOOL = BOOL * keep([(2,1), (1,2), (0,1),(1,0)], lambda neighbour_index: URLL_predicate_list[i]((1,1), neighbour_index, len_tuple)) == [(2,1), (1,2), (0,1),(1,0)]\n",
    "            if BOOL ==0:\n",
    "                print(\"It looks like the part of the neighbours_if_on_an_edge_E_index function to keep in bound indices for the %s edge isn't working\" %edge)\n",
    "        else:\n",
    "            print (\"neighbours_if_on_an_edge_E_index function is A-OK!\")\n",
    "\n",
    "\n",
    "def test_remove_out_of_bound_indices(remove_out_of_bound_indices_func, index_and_neighbours, array_size_tuple, neighbours_if_on_edge_E_index, URLL_edge_predicate_list, **answer):\n",
    "    try:\n",
    "        ans = answer[\"answer\"]\n",
    "        res= remove_out_of_bound_indices(index_and_neighbours, array_size_tuple, neighbours_if_on_edge_E_index, URLL_edge_predicate_list)\n",
    "        if res !=ans:\n",
    "            print(\"The remove_out_of_bound_indices function generated the %s instead of %s. \" %(res,ans))\n",
    "        else:\n",
    "            print(\"The remove_out_of_bound_indices function generated your answer %s .\\n\" % ans)\n",
    "    except(KeyError):\n",
    "        res_2_2_3_3 = remove_out_of_bound_indices( ((2,2), [(1,2),(2,1)]), (3,3), neighbours_if_on_edge_E_index, URLL_edge_predicate_list  )\n",
    "        if res_2_2_3_3 != [(1,2), (2,1)]:\n",
    "            print(\"Default test: when asked to generate neighbours for a lower right corner in a 3-by-3 array, the remove_out_of_bound_indices function generated %s instead\" % res)\n",
    "        else:\n",
    "            print(\"remove_out_of_bound_indices function is A-OK!\")\n",
    "\n",
    "def test_stack(stack_function):\n",
    "    try:\n",
    "        x = [1,2,3];\n",
    "        y = [4,5]\n",
    "        if stack(x,y) ==[(1, 4), (2, 5)]:\n",
    "            print(\"stack_function can handle lists of different lengths\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"stack_function failed to stack things of different lengths\\n\")\n",
    "        print (e)\n",
    "\n",
    "def test_neighbouring_path_spaces(neighbouring_path_spaces, matrix_of_bools, test_index ):\n",
    "    putative_neighbours = neighbouring_path_spaces(co_ordinates_and_neighbouring_indices(matrix_of_bools)[test_index[0]][test_index[1]], matrix_of_bools)\n",
    "    for i in putative_neighbours:\n",
    "        assert matrix_of_bools[i[0]][i[1]]==0\n",
    "#I really like testing things like thist. WAY less friction.                  \n",
    "def test_min_of_F_on_set(test_func):\n",
    "    assert test_func(lambda x:x, [i for i in range(5)]) ==0\n",
    "    assert test_func(lambda x:x, [i+1 for i in range(5)]) !=0\n",
    "    assert test_func(lambda x:x, [i+1 for i in range(5)]) ==0\n",
    "\n",
    "    try:\n",
    "        test_funct(lambda x: x, [])\n",
    "    except(AttributeError, ValueError):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "upper_edge_predicate= lambda index, len_y, len_x: 1 if index[0] == 0 else 0;\n",
    "\n",
    "right_edge_predicate= lambda index, len_y, len_x: 1 if index[1] == len_x else 0\n",
    "\n",
    "lower_edge_predicate= lambda index, len_y, len_x: 1 if index[0] == len_y else 0;\n",
    "\n",
    "left_edge_predicate= lambda index, len_y, len_x: 1 if index[1] == 0 else 0;\n",
    "\n",
    "\n",
    "\n",
    "upper_edge_predicate= lambda node_index, neighbour_index , len_tuple: 0 if node_index[0]==0 and neighbour_index == (node_index[0]-1,node_index[1]) else 1\n",
    "right_edge_predicate= lambda node_index, neighbour_index , len_tuple: 0 if node_index[1]+1==len_tuple[1] and neighbour_index == (node_index[0],node_index[1]+1) else 1\n",
    "lower_edge_predicate= lambda node_index, neighbour_index , len_tuple: 0 if node_index[0]+1==len_tuple[0] and neighbour_index == (node_index[0]+1,node_index[1]) else 1\n",
    "left_edge_predicate= lambda node_index, neighbour_index , len_tuple: 0 if node_index[1]==0 and neighbour_index == (node_index[0],node_index[1]-1) else 1\n",
    "\n",
    "#Iterate over these predicates by plugging them into neighbours_if_on_edge_E_index in order to remove out of bound potential neighbouring indices\n",
    "URLL_edge_predicate_list = [upper_edge_predicate, right_edge_predicate, lower_edge_predicate, left_edge_predicate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Gives AttributeError and ValueError if the list is empty. So check before you use this that there are neighbours!\n",
    "min_of_F_on_set = lambda F, SET: np.min( list(map(F, SET))  )\n",
    "\n",
    "x_is_in_y = lambda x,y:  sum([x==i for i in y])\n",
    "\n",
    "x_intersection_y = lambda x,y:  keep(x,lambda z: x_is_in_y(z,y) )\n",
    "x_disjunction_y = lambda x,y:  keep(x,lambda z: 1-x_is_in_y(z,y) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#takes in a list and a predicate and keeps them if the predicate if true.\n",
    "def keep(ls, pred):\n",
    "    try:\n",
    "        new_list=[]\n",
    "        for i in ls:\n",
    "            if pred(i):\n",
    "                new_list.append(i)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        return new_list\n",
    "    except TypeError:\n",
    "        a= type(ls) != list or type(ls); \n",
    "        b =type(pred) != types.FunctionType\n",
    "        if a or b:\n",
    "            raise TypeError(\" ls and pred are of types %s and %s when they should be of type function (to Bool) and list\\n\" % (type(ls), type(pred))) \n",
    "    except ValueError:\n",
    "        raise ValueError(\"pred should be of type X-->Bool where X is the type of the elements of ls\\n\")\n",
    "\n",
    "#listXlist --> list, stacks the elements length wise. Generates list of len == min(len(x), len(y))\n",
    "stack = lambda x,y:[(x[i],y[i]) for i in range(len(x)) ] if len(x)<= len(y) else [(x[i],y[i]) for i in range(len(y)) ]\n",
    "deep_stack = lambda x,y:   [[(x[i][j],y[i][j]) for j in range(len(x[0]))]  for i in range(len(x)) ]\n",
    "\n",
    "def flat(x):\n",
    "    a = [];\n",
    "    for i in x:\n",
    "        for j in i:\n",
    "            a.append(j);\n",
    "    try:\n",
    "        if type(x) == np.ndarray:\n",
    "            return np.array(a)\n",
    "        else:\n",
    "            return a\n",
    "    except:\n",
    "        return a\n",
    "    \n",
    "random_matrix = lambda x: np.random.randint(0,2,[np.random.randint(1,41), np.random.randint(1,11)]);\n",
    "\n",
    "is_node = np.vectorize(lambda x: 1 if x ==0 else 0);\n",
    "#co_ordinates = lambda x: [(lambda y,X:[ (j,i) for i in range(len(x[j]))] ) (x,j)  for j  in range(len(x))]\n",
    "#OR YOU CAN WRITE \n",
    "co_ordinates = lambda array: np.dstack(np.indices([len(array), len(array[0])]  ))  \n",
    "#Only difference it is an array of np.ndarrays instead of an array of tuples\n",
    "\n",
    "#Take in an array of bools. Get the co-ordinates of each bool, flatten the array and the co-ordinates, stack them, then filter based on whether or not the bool is 0\n",
    "\n",
    "graph_nodes_generator = lambda x: keep( stack(flat(x), flat(co_ordinates(x))) , lambda y: 1 if y[0]==0 else 0)\n",
    "matrix_to_node_values = lambda x:  deep_stack(x, co_ordinates(x))\n",
    "#neighbours_of_node = lambda node, array: \n",
    "\n",
    "\n",
    "def neighbouring_indices_raw(index_tuple):\n",
    "    return [( index_tuple[0]+1, index_tuple[1] ),( index_tuple[0], index_tuple[1]+1 ),( index_tuple[0]-1, index_tuple[1] ),( index_tuple[0], index_tuple[1]-1 )]\n",
    "\n",
    "neighbours_if_on_edge_E_index = lambda index, neighbours, len_tuple, edge_predicate, : keep(neighbours, lambda neighbour_index: edge_predicate(index, neighbour_index, len_tuple))\n",
    "\n",
    "#This function takes in a [index, its neighbours], the size of the array containgint the index  in tuple format,\n",
    "#the function for stripping awaypotential out of bound neighbours for edge E and the edge_predicate_list in order \n",
    "#(upper, right, lower, left) to use the former function. It returns the neighbours after removing potential out of \n",
    "#bound neighbours i.e.\n",
    "#RETURN TYPE LIST_TUPLE\n",
    "def remove_out_of_bound_indices(index_and_neighbours, len_tuple, neighbours_if_on_edge_E_index, URLL_edge_predicate_list):\n",
    "    node_index = index_and_neighbours[0];\n",
    "    neighbours = index_and_neighbours[1];\n",
    "    for i in URLL_edge_predicate_list:\n",
    "        neighbours = neighbours_if_on_edge_E_index(node_index, neighbours, len_tuple, i)\n",
    "    return neighbours\n",
    "\n",
    "#Take in a node, spit out its potential neighbours after accounting for bounds. \n",
    "    #Check it's neighbours for whether or not they're nodes \n",
    "        #keep them if they're not\n",
    "        #return the result\n",
    "    \n",
    "\n",
    "neighbouring_indices = lambda x:  [[remove_out_of_bound_indices(i, (len(x), len(x[0])), neighbours_if_on_edge_E_index, URLL_edge_predicate_list ) for i in j] for j in   deep_stack( co_ordinates(x),[[neighbouring_indices_raw(Y) for Y in Z]  for Z in co_ordinates(x)])]\n",
    "\n",
    "co_ordinates_and_neighbouring_indices = lambda x: deep_stack(co_ordinates(x), neighbouring_indices(x))\n",
    "\n",
    "\n",
    "    \n",
    "neighbouring_path_spaces = lambda index_and_neighbours, array: keep(index_and_neighbours[1],  lambda index: 1- array[index[0]] [index [1]] )\n",
    "\n",
    "node_values_and_neighbours = lambda x, index_and_neighbors_array:  deep_stack(x, [  [neighbouring_path_spaces( index_and_neighbors_array[i][j], x)  for j in range(len(x[0]))  ]  for i in range(len(x))] )\n",
    "\n",
    "\n",
    "\n",
    "def compute_cost_to_go_from_start_to_x(filled_in_neighbours_of_x, path_costs):\n",
    "    \n",
    "    return min_of_F_on_set( lambda y: 1+ path_costs[y[0]][y[1]]  , filled_in_neighbours_of_x )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_neighbours_of_index = lambda x, index: neighbouring_path_spaces(co_ordinates_and_neighbouring_indices(x)[index[0]][index[1]], x)\n",
    "\n",
    "def compute_costs_to_neighbours_from_start_node(start_node, matrix, temp_stack, path_costs):\n",
    "    i = start_node[0]; j = start_node[1]\n",
    "    path_costs[i][j] = 1;\n",
    "    neighbours = neighbouring_path_spaces(co_ordinates_and_neighbouring_indices(matrix)[i][j], matrix)\n",
    "    \n",
    "    for n in neighbours:\n",
    "        n_i = n[0];n_j = n[1]\n",
    "        n_neigh = neighbouring_path_spaces(co_ordinates_and_neighbouring_indices(matrix)[n_i][n_j], matrix )\n",
    "        if compute_cost_to_go_from_start_to_x(n_neigh,path_costs) < path_costs[n_i][n_j]:\n",
    "            path_costs[n_i][n_j] = compute_cost_to_go_from_start_to_x(n_neigh, path_costs)\n",
    "            temp_stack.append(n)\n",
    "        else:\n",
    "            pass\n",
    "    return(path_costs, temp_stack)\n",
    "\n",
    "\n",
    "def update_path_costs(matrix, temp_stack, perm_stack,  path_costs, ):\n",
    "    stack_2 = []\n",
    "#    remember last node in temp_stack\n",
    "    len_1 = len(temp_stack)\n",
    "#    #This should end once you've gone through all the items in the prior turn.\n",
    "    for i in range(len_1):\n",
    "        try:\n",
    "            node = temp_stack[0];\n",
    "            index = temp_stack.pop(0);\n",
    "            neighbours = get_neighbours_of_index(matrix, node)\n",
    "\n",
    "            for n in neighbours:\n",
    "\n",
    "                n_i = n[0];n_j = n[1]\n",
    "                n_neigh = get_neighbours_of_index(matrix, n)\n",
    "                if compute_cost_to_go_from_start_to_x(n_neigh, path_costs) <path_costs[n_i][n_j]:\n",
    "                    path_costs[n_i][n_j] = compute_cost_to_go_from_start_to_x(n_neigh, path_costs)\n",
    "\n",
    "                    if x_is_in_y(n, temp_stack):\n",
    "                        pass;\n",
    "                    else:\n",
    "                        temp_stack.append(n)\n",
    "                else:\n",
    "                    pass\n",
    "                stack_2.append(n);\n",
    "        except(IndexError):\n",
    "            pass\n",
    "    perm_stack.append(stack_2)\n",
    "    return(path_costs, temp_stack, perm_stack)\n",
    "\n",
    "def forward_pass(matrix, start_node, path_cost, temp_stack, perm_stack):\n",
    "    \n",
    "    path_cost[start_node[0]][start_node[1]] = 0;\n",
    "    compute_costs_to_neighbours_from_start_node(start_node, matrix, temp_stack, path_cost)\n",
    "    while temp_stack!=[]:\n",
    "        update_path_costs(matrix, temp_stack, perm_stack, path_cost)\n",
    "\n",
    "    return path_cost\n",
    "\n",
    "\n",
    "def compute_shortest_path(matrix, path_cost_forward, path_cost_backward, cost):\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[0])):\n",
    "            if matrix[i][j]==1:\n",
    "                neigh = get_neighbours_of_index(matrix, (i,j))\n",
    "                if len(neigh)>0:\n",
    "                    x = 1+np.min([[ path_cost_backward[a[0]][a[1]] + path_cost_forward[b[0]][b[1]]  for a in neigh ] for b in neigh])\n",
    "                    if x<cost:\n",
    "                        cost = x\n",
    "    return cost\n",
    "\n",
    "def solution(matrix):\n",
    "    temp_stack = [];\n",
    "    perm_stack = []\n",
    "    start_node = (0,0);\n",
    "    cost_to_go_from_start_to_x  = [ [np.inf for j in range(len(matrix[0]))] for i in range(len(matrix))   ]\n",
    "    cost_to_go_from_start_to_x_1 = [ [np.inf for j in range(len(matrix[0]))] for i in range(len(matrix))   ]\n",
    "\n",
    "    path_cost_forward=  forward_pass(matrix, start_node, cost_to_go_from_start_to_x, perm_stack, temp_stack)\n",
    "    path_cost_backward = forward_pass(matrix, (len(matrix)-1, len(matrix[0])-1), cost_to_go_from_start_to_x_1, [], [])\n",
    "    cost = path_cost_backward[0][0]+1\n",
    "    return compute_shortest_path(matrix, path_cost_forward, path_cost_backward, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution([[0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution([[0, 1, 1, 0], [0, 0, 0, 1], [1, 1, 0, 0], [1, 1, 1, 0]])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
